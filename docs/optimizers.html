---

title: Optimizers


keywords: fastai
sidebar: home_sidebar

summary: "This module implements interfaces and several known optimizers that can be tested against different functions"
description: "This module implements interfaces and several known optimizers that can be tested against different functions"
nb_path: "02_optimizers.ipynb"
---
<!--

#################################################
### THIS FILE WAS AUTOGENERATED! DO NOT EDIT! ###
#################################################
# file to edit: 02_optimizers.ipynb
# command to build the docs after a change: nbdev_build_docs

-->

<div class="container" id="notebook-container">
        
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

<div class="output_wrapper">
<div class="output">

<div class="output_area">


<div class="output_markdown rendered_html output_subarea ">
<h2 id="optimize" class="doc_header"><code>class</code> <code>optimize</code><a href="https://github.com/clungu/optimisations/tree/master/optimisations/optimizers.py#L44" class="source_link" style="float:right">[source]</a></h2><blockquote><p><code>optimize</code>(<strong><code>function</code></strong>)</p>
</blockquote>

</div>

</div>

</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">optimisations.functions</span> <span class="kn">import</span> <span class="n">himmelblau</span>
<span class="kn">from</span> <span class="nn">jax.experimental.optimizers</span> <span class="kn">import</span> <span class="n">sgd</span>

<span class="p">(</span>
    <span class="n">optimize</span><span class="p">(</span><span class="n">himmelblau</span><span class="p">())</span>
        <span class="o">.</span><span class="n">using</span><span class="p">(</span><span class="n">sgd</span><span class="p">(</span><span class="n">step_size</span><span class="o">=</span><span class="mf">0.001</span><span class="p">))</span>
        <span class="o">.</span><span class="n">start_from</span><span class="p">([</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">])</span>
        <span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">10</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

<div class="output_wrapper">
<div class="output">

<div class="output_area">

<div class="output_subarea output_stream output_stderr output_text">
<pre>WARNING:absl:No GPU/TPU found, falling back to CPU. (Set TF_CPP_MIN_LOG_LEVEL=0 and rerun for more info.)
</pre>
</div>
</div>

<div class="output_area">



<div class="output_text output_subarea output_execute_result">
<pre>[(1.0, 1.0), (1.0460000038146973, 1.0379999876022339), (1.0928562879562378, 1.0759831666946411), (1.1405162811279297, 1.1138836145401), (1.1889206171035767, 1.1516332626342773), (1.2380036115646362, 1.1891623735427856), (1.2876930236816406, 1.2264001369476318), (1.3379102945327759, 1.2632750272750854), (1.388570785522461, 1.299715518951416), (1.4395838975906372, 1.3356506824493408), (1.4908537864685059, 1.371010661125183)]</pre>
</div>

</div>

</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p><code>JAX</code> is kind of rough, the optimizers (for now) sit inside the <code>experimental</code> submodule which means that their API might change in the future.</p>
<p>An optimizer is a function that has some initialization parameters, and which returns 3 functions:</p>
<ul>
<li><code>init</code> - is a function to which you pass all the initial values of your hidden parameters and you get back a <code>state</code> object, which is a <code>pytree</code> structure (some internal representation). This is a bit confusing and I'm guessing this intermediate <code>pytree</code> thing might disappear from the API in the near future.</li>
<li><code>update</code> - is the function that does a single update pass over the whole parameters. It receives as inputs:<ul>
<li><code>i</code> - the count of the current iteration. This usefull because, depending on the optimizer implementation, you can have different learning properties at each iteration (like some annealing strategy for the learning rate, etc..)</li>
<li><code>g</code> - the gradient values (you get these by extracting the params from the <code>state</code> function, using the <code>get_params</code> function bellow (these are the variables that will get updated by the optimizer). Then pass these onto your gradient function and its results as input to this function. </li>
<li><code>state</code> - that <code>pytre</code> structure that you've got after calling <code>init</code> (and which you'll contrantly replace with the result of this <code>update</code> function call)</li>
</ul>
</li>
<li><code>get_params</code> - a <code>utils</code> function that extracts the param object from a known <code>state</code> object (which is a <code>pytree</code>). </li>
</ul>

</div>
</div>
</div>
<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>So the full flow of the above, in code is shown bellow:</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">jax.experimental.optimizers</span> <span class="kn">import</span> <span class="n">sgd</span>

<span class="n">init</span><span class="p">,</span> <span class="n">update</span><span class="p">,</span> <span class="n">get_params</span> <span class="o">=</span> <span class="n">sgd</span><span class="p">(</span><span class="n">step_size</span><span class="o">=</span><span class="mf">0.001</span><span class="p">)</span> <span class="c1"># instantiate the optimizer</span>

<span class="n">state</span> <span class="o">=</span> <span class="n">init</span><span class="p">((</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">))</span> <span class="c1"># initialize the optimizer state with some initial weights and get a state back</span>
<span class="nb">print</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">get_params</span><span class="p">(</span><span class="n">state</span><span class="p">))</span>    <span class="c1"># you use this function to extract the weight values from the state object</span>

<span class="n">grad_function</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">himmelblau</span><span class="p">(),</span> <span class="n">argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>  <span class="c1"># you build the function that will compute your gradients</span>
                                                    <span class="c1"># The argnum part is needed because we have to specify that there are two parameters the parent function uses, and we want the derivative to both of them.</span>
    
<span class="n">state</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">grad_function</span><span class="p">(</span><span class="o">*</span><span class="n">get_params</span><span class="p">(</span><span class="n">state</span><span class="p">)),</span> <span class="n">state</span><span class="p">)</span>    <span class="c1"># you call update with a iteration number, the gradient of the params, and the previous state and you get back a new state </span>
<span class="nb">print</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">grad</span>
<span class="kn">from</span> <span class="nn">optimisations.functions</span> <span class="kn">import</span> <span class="n">himmelblau</span>

<span class="n">grad</span><span class="p">(</span><span class="n">himmelblau</span><span class="p">(),</span> <span class="n">argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))(</span><span class="o">*</span><span class="n">get_params</span><span class="p">(</span><span class="n">state</span><span class="p">))</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>And you can see the result of running 10 iterations of the above, in a loop. It moves to some direction, and I'm sure you're eager to see where, on the graph...</p>

</div>
</div>
</div>
    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="n">grad_function</span> <span class="o">=</span> <span class="n">grad</span><span class="p">(</span><span class="n">himmelblau</span><span class="p">(),</span> <span class="n">argnums</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="k">def</span> <span class="nf">run</span><span class="p">():</span>
    <span class="n">state</span> <span class="o">=</span> <span class="n">init</span><span class="p">((</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">2.</span><span class="p">))</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">10</span><span class="p">):</span>
        <span class="n">params</span> <span class="o">=</span> <span class="n">get_params</span><span class="p">(</span><span class="n">state</span><span class="p">)</span>
        <span class="k">yield</span> <span class="n">params</span>
        <span class="n">state</span> <span class="o">=</span> <span class="n">update</span><span class="p">(</span><span class="n">i</span><span class="p">,</span> <span class="n">grad_function</span><span class="p">(</span><span class="o">*</span><span class="n">params</span><span class="p">),</span> <span class="n">state</span><span class="p">)</span>
    
<span class="p">[(</span><span class="nb">float</span><span class="p">(</span><span class="n">x</span><span class="p">),</span> <span class="nb">float</span><span class="p">(</span><span class="n">y</span><span class="p">))</span> <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">run</span><span class="p">()]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

    {% raw %}
    
<div class="cell border-box-sizing code_cell rendered">
<div class="input">

<div class="inner_cell">
    <div class="input_area">
<div class=" highlight hl-ipython3"><pre><span></span><span class="k">class</span> <span class="nc">optimize_multi</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">function</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">function</span> <span class="o">=</span> <span class="n">function</span>

    <span class="k">def</span> <span class="nf">using</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">optimizers</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span> <span class="o">=</span> <span class="n">optimizers</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">start_from</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">params</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">params</span> <span class="o">=</span> <span class="n">params</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">def</span> <span class="nf">tolist</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="p">[</span><span class="n">optimize</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">function</span><span class="p">)</span><span class="o">.</span><span class="n">using</span><span class="p">(</span><span class="n">optimizer</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="n">name</span><span class="p">,</span> <span class="n">derivatives_based</span><span class="o">=</span><span class="n">derivatives_based</span><span class="p">)</span><span class="o">.</span><span class="n">start_from</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">params</span><span class="p">)</span> <span class="k">for</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">name</span><span class="p">,</span> <span class="n">derivatives_based</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">optimizers</span><span class="p">]</span>
</pre></div>

    </div>
</div>
</div>

</div>
    {% endraw %}

<div class="cell border-box-sizing text_cell rendered"><div class="inner_cell">
<div class="text_cell_render border-box-sizing rendered_html">
<p>When you want to compare the performance of multiple optimizers.</p>

</div>
</div>
</div>
</div>
 

